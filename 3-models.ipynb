{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqmo0xIbf1YZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_selected = ['department', 'region', 'awards_won?', \n",
        "                     'previous_year_rating', 'KPIs_met >80%',\n",
        "                      'avg_training_score', 'total_score', 'pca_combined']\n",
        "                      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn5AE-SAc-85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_selected_categorical = ['department', 'region', 'awards_won?','KPIs_met >80%']\n",
        "features_selected_ordinal = ['previous_year_rating']\n",
        "features_selected_numerical = ['avg_training_score', 'total_score', 'pca_combined']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP9B9AeTf3uZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save to disk\n",
        "# # X.loc[:, features_selected] -> to store only selected features\n",
        "# X.to_csv(path_or_buf='/content/drive/My Drive/Colab Notebooks/data/HR_processed.csv', index=False)\n",
        "# pd.DataFrame(data=train_index,columns=['train_index']).to_csv(\n",
        "#     path_or_buf='/content/drive/My Drive/Colab Notebooks/data/HR_train_index.csv',\n",
        "#     index=False)\n",
        "# pd.DataFrame(data=validate_index,columns=['validate_index']).to_csv(\n",
        "#     path_or_buf='/content/drive/My Drive/Colab Notebooks/data/HR_validate_index.csv',\n",
        "#     index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymblaZ5wlfEd",
        "colab_type": "text"
      },
      "source": [
        "# Utility Methods for Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM7aQV4n6jPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, classes, \n",
        "                          title=None, for_data='train'):\n",
        "    '''\n",
        "    for_data = Train or CV or Test\n",
        "    '''\n",
        "    \n",
        "    if not title:\n",
        "        title = 'Confusion Matrix'\n",
        "    \n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Fliping is needed, because originally\n",
        "    # True/Actual labels are on Y-Axis and \n",
        "    # Predicted labels are on X-Axis, \n",
        "    # but we need Predicted labels on Y-Axis\n",
        "    # flip horizontally: axis = 1\n",
        "    cm = np.flip(np.flip(cm, 0),1) #changed\n",
        "    \n",
        "    # Since we have flipped Actual & Predicted\n",
        "    # We need to flip the class Labels aswell\n",
        "    # the labels are in Lexicographical order in\n",
        "    # data. Hence 0(Rejected) followed by 1(Accepted).\n",
        "    classes = np.flip(classes)\n",
        "    \n",
        "    #classes = classes[unique_labels(y_true, y_pred)]\n",
        "\n",
        "    if for_data.lower().strip() == 'test':\n",
        "        cmap = plt.cm.Oranges\n",
        "    else:\n",
        "        cmap = plt.cm.Blues\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    \n",
        "    #ax.figure.colorbar(im, ax=ax) # Equivalent to 'cbar' in sns.heatmap()\n",
        "    \n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[0]),# [1]\n",
        "           yticks=np.arange(cm.shape[1]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='Predicted label',\n",
        "           xlabel='True label')# changed\n",
        "    \n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "    \n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[1]):\n",
        "        for j in range(cm.shape[0]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    \n",
        "    plt.show()\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JquTm8TCQUzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stratified_sample(y, sample_size):\n",
        "    '''\n",
        "        Parameters :\n",
        "        ---------------------------------------\n",
        "        y : Target label\n",
        "\n",
        "        sample_size : Integer or Float value indicating \n",
        "                      number of samples to be drawn\n",
        "\n",
        "        Return:\n",
        "        --------------------------------\n",
        "        list of index of samples drawn\n",
        "    '''\n",
        "\n",
        "    if not isinstance(y, pd.Series):\n",
        "        y = pd.Series(y)\n",
        "\n",
        "    # check if sample size or sample fraction provided\n",
        "    # numbers.Integral --> needed in case of Long integers\n",
        "    if isinstance(sample_size, int):\n",
        "        if sample_size > len(y):\n",
        "            raise ValueError('sample_size should be less than or equal to length of y.')\n",
        "    elif isinstance(sample_size, float):\n",
        "        sample_size = math.ceil(len(y) * sample_size)\n",
        "        int_flag = False\n",
        "    else:\n",
        "        raise ValueError('sample_size can only be integer or float')\n",
        "\n",
        "    # no of instances of each label\n",
        "    vc = y.value_counts()\n",
        "    \n",
        "    # count fraction of each label in original data\n",
        "    vc = vc / len(y)\n",
        "    \n",
        "    # holds the index of the subsample drawn\n",
        "    # this wil be returned\n",
        "    sub_sample_index = []\n",
        "\n",
        "    for label in vc.index:\n",
        "        # calculate no of samples for each class to be returned\n",
        "        count = math.ceil(sample_size * vc[label])\n",
        "\n",
        "        # draw the sample (index)\n",
        "        # list() => index data is not supported by random.sample()\n",
        "        sub_sample = random.sample(list(y[y==label].index), count) \n",
        "\n",
        "        sub_sample_index.extend(sub_sample)\n",
        "\n",
        "    \n",
        "    return sub_sample_index\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp4H2nBcllUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "   \n",
        "def tuned_model(tuned_base_model, X, y):\n",
        "\n",
        "    tuned_base_model = tuned_base_model.fit(X, y)\n",
        "\n",
        "    calibrated_model = CalibratedClassifierCV(base_estimator=tuned_base_model, cv='prefit')\n",
        "    calibrated_model = calibrated_model.fit(X, y)\n",
        "\n",
        "    return tuned_base_model, calibrated_model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}